<script src="https://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
		font-weight: 300;
		font-size: 18px;
		margin-left: auto;
		margin-right: auto;
		width: 1100px;
	}

	h1 {
		font-weight: 300;
	}

	.disclaimerbox {
		background-color: #eee;
		border: 1px solid #eeeeee;
		border-radius: 10px;
		-moz-border-radius: 10px;
		-webkit-border-radius: 10px;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px;
		-moz-border-radius: 10px;
		-webkit-border-radius: 10px;
	}

	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px;
		-moz-border-radius: 10px;
		-webkit-border-radius: 10px;
	}

	img.rounded {
		border: 0px solid #eeeeee;
		border-radius: 10px;
		-moz-border-radius: 10px;
		-webkit-border-radius: 10px;
	}

	a:link,
	a:visited {
		color: #1367a7;
		text-decoration: none;
	}

	a:hover {
		color: #208799;
	}

	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}

	.layered-paper-big {
		/* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
			0px 0px 1px 1px rgba(0, 0, 0, 0.35),
			/* The top layer shadow */
			5px 5px 0 0px #fff,
			/* The second layer */
			5px 5px 1px 1px rgba(0, 0, 0, 0.35),
			/* The second layer shadow */
			10px 10px 0 0px #fff,
			/* The third layer */
			10px 10px 1px 1px rgba(0, 0, 0, 0.35),
			/* The third layer shadow */
			15px 15px 0 0px #fff,
			/* The fourth layer */
			15px 15px 1px 1px rgba(0, 0, 0, 0.35),
			/* The fourth layer shadow */
			20px 20px 0 0px #fff,
			/* The fifth layer */
			20px 20px 1px 1px rgba(0, 0, 0, 0.35),
			/* The fifth layer shadow */
			25px 25px 0 0px #fff,
			/* The fifth layer */
			25px 25px 1px 1px rgba(0, 0, 0, 0.35);
		/* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}

	.paper-big {
		/* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
			0px 0px 1px 1px rgba(0, 0, 0, 0.35);
		/* The top layer shadow */

		margin-left: 10px;
		margin-right: 45px;
	}

	.layered-paper {
		/* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
			0px 0px 1px 1px rgba(0, 0, 0, 0.35),
			/* The top layer shadow */
			5px 5px 0 0px #fff,
			/* The second layer */
			5px 5px 1px 1px rgba(0, 0, 0, 0.35),
			/* The second layer shadow */
			10px 10px 0 0px #fff,
			/* The third layer */
			10px 10px 1px 1px rgba(0, 0, 0, 0.35);
		/* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}

	.vert-cent {
		position: relative;
		top: 50%;
		transform: translateY(-50%);
	}

	hr {
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}
</style>

<html>

<head>
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=UA-96559401-4"></script>
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag() { dataLayer.push(arguments); }
		gtag('js', new Date());

		gtag('config', 'UA-96559401-4');
	</script>
	<title>BlendGAN: Implicitly GAN Blending for Arbitrary Stylized Face Generation</title>
	<meta property="og:image" content="" />
	<meta property="og:title" content="BlendGAN: Implicitly GAN Blending for Arbitrary Stylized Face Generation" />
</head>

<body>
	<br>
	<center>
		<span style="font-size:34px">BlendGAN: Implicitly GAN Blending for Arbitrary Stylized Face Generation</span><br>
		<span style="font-size:25px;line-height:2.0">NeurIPS 2021</span><br>
		<table align=center width=1100px>
			<tr>
				<td align=center width=250px>
					<span style="font-size:20px"><a
							href="https://scholar.google.com/citations?user=IYx0IbgAAAAJ">Mingcong
							Liu</a></span>&nbsp;&nbsp;&nbsp;
					<span style="font-size:20px"><a href="https://scholar.google.com/citations?user=GGPvOP4AAAAJ">Qiang
							Li</a></span>&nbsp;&nbsp;&nbsp;
					<span style="font-size:20px"><a href="https://github.com/ZekuiQin">Zekui
							Qin</a></span>&nbsp;&nbsp;&nbsp;
					<span style="font-size:20px"><a href="">Guoxin
							Zhang</a></span>&nbsp;&nbsp;&nbsp;
					<span style="font-size:20px"><a href="">Pengfei
							Wan</a></span>&nbsp;&nbsp;&nbsp;
					<span style="font-size:20px"><a href="https://sites.google.com/view/zhengwen-kwai">Wen
							Zheng</a></span>&nbsp;&nbsp;&nbsp;
				</td>
			</tr>
		</table>
		<table align=center width=850px>
			<tr>
				<td align=center width=175px>
					<center>
						<span style="font-size:20px"></span>
					</center>
				</td>
				<td align=center width=200px>
					<center>
						<span style="font-size:20px">Y-tech, Kuaishou Technology</span>
					</center>
				</td>
				<td align=center width=175px>
					<center>
						<span style="font-size:20px"></span>
					</center>
				</td>
			</tr>

		</table>
		<table>
			<tr>
				<td align=center width=200px> <span style="font-size:15pt">
						<center>
							<a href="https://arxiv.org/abs/2110.11728">[Paper]</a>

						</center>
				</td>
				<td align=center width=200px> <span style="font-size:15pt">
						<center>
							<a href="https://github.com/onion-liu/BlendGAN">[Code]</a>

						</center>
				</td>
				<td align=center width=200px> <span style="font-size:15pt">
						<center>

							<a href="./index_files/bibtex_blendgan.txt">[Bibtex]</a>
						</center>
				</td>
			</tr>
		</table>

		<!-- 	  		  <table align=center width=1100px>
	  			  <tr>
	  	              <td align=center width=275px>
	  					<center>
				          	<span style="font-size:18px"></span>
		  		  		</center>
		  		  	  </td>
	  	              <td align=center width=225px>
	  					<center>
	  						<span style="font-size:22px">Code <a href='https://github.com/richzhang/PerceptualSimilarity'> [GitHub]</a></span>
		  		  		</center>
		  		  	  </td>
	  	              <td align=center width=225px>
	  					<center>
	  						<span style="font-size:22px">CVPR 2018<a href="http://arxiv.org/abs/1801.03924"> [Paper]</a></span>
		  		  		</center>
		  		  	  </td>
	  	              <td align=center width=275px>
	  					<center>
				          	<span style="font-size:18px"></span>
		  		  		</center>
		  		  	  </td>
			  </table> -->
	</center>

	<!--   		  <table align=center width=1100px>
  			  <tr>
  	              <td width=400px>
  					<center>
  	                	<img class="rounded" src = "./index_files/fig1_v2.jpg" width="1100px"></img>
  	                	<br>
					</center>
  	              </td>
  	              </tr>
  	              </table>

  		  <br>
		  <hr>
 -->

	<table align=center width=1100px>
		<tr>
			<td width=400px>
				<center>
					<img class="rounded" src="./index_files/teaser.jpg" width="1100px"></img>
					<br>
				</center>
			</td>
		</tr>
	</table>

	<hr>


	<table align=center width=900px>
		<center>
			<h1>Abstract</h1>
		</center>
		<tr>
			Generative Adversarial Networks (GANs) have made a dramatic leap in high-fidelity image synthesis and
			stylized face generation. Recently, a layer-swapping mechanism has been developed to improve the stylization
			performance. However, this method is incapable of fitting arbitrary styles in a single model and requires
			hundreds of style-consistent training images for each style. To address the above issues, we propose
			BlendGAN for arbitrary stylized face generation by leveraging a flexible blending strategy and a generic
			artistic dataset. Specifically, we first train a self-supervised style encoder on the generic artistic
			dataset to extract the representations of arbitrary styles. In addition, a weighted blending module (WBM) is
			proposed to blend face and style representations implicitly and control the arbitrary stylization effect. By
			doing so, BlendGAN can gracefully fit arbitrary styles in a unified model while avoiding case-by-case
			preparation of style-consistent training images. To this end, we also present a novel large-scale artistic
			face dataset AAHQ. Extensive experiments demonstrate that BlendGAN outperforms state-of-the-art methods in
			terms of visual quality and style diversity for both latent-guided and reference-guided stylized face
			synthesis.
			<br>
		</tr>
		<br>
		<hr>

		<center>
			<h1>Overview</h1>
		</center>
		<table align=center width=1100px>
			<tr>
				<td width=400px>
					<center>
						<img class="rounded" src="./index_files/architecture.jpg" width="1100px"></img>
						<br>
					</center>
				</td>
			</tr>
		</table>
		<tr>
			The style encoder E<sub>style</sub> extracts the style latent code z<sub>s</sub> of a reference style image.
			The face latent code z<sub>f</sub> is randomly sampled from the standard Gaussian distribution. Two MLPs
			transform face and style latent codes into their W spaces separately, then they are combined by the
			weighted blending module (WBM) and fed into generator G to synthesise natural and stylized face
			images. Three discriminators are used in our method. The face discriminator D<sub>face</sub> distinguishes
			between
			real and fake natural-face images, the style discriminator D<sub>style</sub> distinguishes between real and
			fake
			stylized-face images, and the style latent discriminator D<sub>style_latent</sub> predicts whether the
			stylized-face image is consistent with the style latent code z<sub>s</sub>.
			<br>
		</tr>

		<hr>

		<!-- <center>
			<h1>Video</h1>
		</center>
		<table align="center" width="700px">
			<tbody>
				<tr>

					<td align="center" width="700px">
						<center>
							<iframe width="1120" height="630" src="https://www.youtube.com/embed/0elW11wRNpg"
								frameborder="0"
								allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
								allowfullscreen></iframe>
						</center>
					</td>
				</tr>
			</tbody>
		</table>

		<hr> -->

		<table align=center width=500 px>
			<center>
				<h1>Paper</h1>
			</center>
			<tr>
				<td><a href=""><img class="layered-paper-big" style="height:175px" src="./index_files/thumbnail.jpg" /></a>
				</td>
				<td><span style="font-size:12pt">M. Liu, Q. Li, Z. Qin, G. Zhang, <br> P. Wan, W. Zheng.</span><br>
					<b><span style="font-size:12pt">BlendGAN: Implicitly GAN Blending for Arbitrary Stylized Face
							Generation.</span></b><br>
					<span style="font-size:12pt">NeurIPS, 2021.</span>
				</td>
				</td>
			</tr>
		</table>
		<br>
		<table align=center width=600px>
			<tr>
				<td><span style="font-size:14pt">
						<center>
							<a href="https://arxiv.org/abs/2110.11728">[Paper]</a> |
							<a href="./index_files/bibtex_blendgan.txt">[Bibtex]</a>
						</center>
				</td>
			</tr>
		</table>
		<br>
		<hr>

		<table align=center width=1100px>
			<tr>
				<td width=400px>
					<left>
						<center>
							<h1>Acknowledgements</h1>
						</center>
						We sincerely thank all the reviewers for their comments. We also thank Zhenyu Guo for help in
						preparing the comparison to StarGANv2.
					</left>
				</td>
			</tr>
		</table>

		<br><br>

		<!-- Global site tag (gtag.js) - Google Analytics -->
		<!-- <script async src="https://www.googletagmanager.com/gtag/js?id=UA-75863369-5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-75863369-5');
</script>
 -->


</body>

</html>